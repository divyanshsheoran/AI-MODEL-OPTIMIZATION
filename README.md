# AI Model Optimization Project

This project investigates model compression techniques (quantization, pruning, distillation) to optimize large-scale AI models for deployment in resource-constrained environments. The baseline model used is MobileNetV2 on the CIFAR-10 dataset using PyTorch.

Folder Structure:
- notebooks/: Jupyter notebooks for experiments
- scripts/: Python scripts for training and evaluation
- models/: Saved trained models
- results/: Metrics and graphs
- report/: Dissertation docs and notes
